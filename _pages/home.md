---
layout: default
urltitle: "1st ICML Workshop on In-Context Learning (ICL @ ICML 2024)"
title: "1st ICML Workshop on In-Context Learning (ICL @ ICML 2024)"
categories: workshop, icml, in-context learning, 2024
permalink: /
bibtex: true
paper: true
acknowledgements: ""
---

<br/>
<div class="row reverse">
  <div class="col-xs-12 col-md-7">
    <h1>1st ICML Workshop on In-Context Learning (ICL @ ICML 2024)</h1>
    <br>
<p>
In-context learning (ICL) is an emerging capability of large-scale models, including large language models (LLMs) like GPT-3, to acquire new capabilities directly from the context of an input example without separate training or fine-tuning, enabling these models to adapt rapidly to new tasks, datasets, and domains. This workshop brings together diverse perspectives on this new paradigm to assess progress, synthesize best practices, and chart open problems. Core topics will include architectural and other inductive biases enabling in-context skill acquisition, and reliable evaluation of ICL in application domains including reinforcement learning, representation learning, and safe and reliable machine learning.
</p>
    <p>
    <b>The workshop will take place on Saturday, July 27th, 2024 at Room Lehar 4, Messe Wien Exhibition Congress Center, Vienna.</b>
    </p>
    <p>
      In case of any issues or questions, feel free to email the organizers at <a href="mailto:iclworkshop@googlegroups.com" class="red">iclworkshop@googlegroups.com</a>.
    </p>
  </div>
  <div class="col-md-1 hidden-xs">
  </div>
  <div class="col-xs-12 col-md-4">
    <img class="cover" src="/static/img/cover.png">
  </div>
</div>

<br/>

<div class="row">
    <div class="col-xs-8">
        
    </div>

</div>

<div class="row" id="schedule">
  <div class="col-xs-12">
    <h2>Schedule</h2>
    <br/>
    <p> All times listed below are in Central European Summer Time (CEST).  </p>
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>8:30 - 9:00 AM</td>
          <td>
            Coffee Break
          </td>
        </tr>
        <tr>
          <td>9:00 - 9:05 AM</td>
          <td>
            Opening Remarks
          </td>
        </tr>
        <tr>
          <td>9:05 - 9:45 AM</td>
          <td>
            Invited Talk "Towards Understanding the Modern Alchemy"<br/>
            <i>Ekin Akyürek</i>
          </td>
        </tr>
        <tr>
          <td>9:45 - 10:25 AM</td>
          <td>
            Invited Talk "What do you need for in-context learning? Data, subcircuits, and dynamics"<br/>
            <i>Stephanie Chan</i>
          </td>
        </tr>
        <tr>
          <td>10:25 - 11:15 AM</td>
          <td>
            Poster Session + Break <br/>
          </td>
        </tr>
        <tr>
          <td>11:15 - 11:20 AM</td>
          <td>
            Spotlight Awards Ceremony by QuantCo<br/>
          </td>
        </tr>
        <tr>
          <td>11:20 - 11:30 AM</td>
          <td>
            Spotlight Paper: A Theoretical Understanding of Self-Correction through In-context Alignment
          </td>
        </tr>
        <tr>
          <td>11:30 - 11:40 AM</td>
          <td>
            Spotlight Paper: Transformers Learn Temporal Difference Methods for In-Context Reinforcement Learning 
          </td>
        </tr>
        <tr>
          <td>11:40 - 11:50 AM</td>
          <td>
            Spotlight Paper: LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language
          </td>
        </tr>
        <tr>
          <td>11:50 AM - 12:30 PM</td>
          <td>
            Invited Talk: "ICL for Bayesians & TabPFN"<br/>
            <i>Samuel Müller</i>
          </td>
        </tr>
        <tr>
          <td>12:30 - 2:00 PM</td>
          <td>
            Lunch Break
          </td>
        </tr>
        <tr>
          <td>2:00 - 2:40 PM</td>
          <td>
            Invited Talk: "In-Context Deductive Reasoning"<br/>
            <i>Mehran Kazemi</i>
          </td>
        </tr>
        <tr>
          <td>2:40 - 3:20 PM</td>
          <td>
            Invited Talk: "Exploring Model Expressivity and Optimization Landscape in in-context Learning"<br/>
            <i>Yingcong Li</i>
          </td>
        </tr>
        <tr>
          <td>3:20 - 4:15 PM</td>
          <td>
            Poster Session
          </td>
        </tr>
        <tr>
          <td>3:30 - 4:00 PM</td>
          <td>
            Coffee Break
          </td>
        </tr>
        <tr>
          <td>4:15 - 4:55 PM</td>
          <td>
            Panel Discussion <br/>
          </td>
        </tr>
        <tr>
          <td>4:55 - 5:00 PM</td>
          <td>
            Closing Remarks
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<div class="row" id="dates">
  <div class="col-xs-12">
    <h2>Important Dates</h2>
  </div>
</div>

<br>
<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
        <tr>
          <!-- Neurips Main Conference Full Paper Submission Deadline	May 22 '24 08:00 PM UTC            -->
          <td><b>Submission Deadline</b></td>
          <td>Monday, May 27th, 2024, Anywhere on Earth (AoE)</td>
        </tr>
        <tr>
          <td><b>Decision Notification</b></td>
          <td>Monday, June 17th, 2024</td>
        </tr>
        <tr>
<!--          <td>Deadline for complimentary registration applications</td>
          <td>10.03.2024</td>-->
        </tr>
        <tr>
          <td><b>Camera-ready Deadline</b></td> <!--         & complimentary registration notifications -->
          <td>Sunday, July 21st, 2024, Anywhere on Earth (AoE)</td>
        </tr>
        <!-- Need to determine if ICML supports videos for workshops.
        <tr>
          <td>Paper Video Submission Deadline</td>
          <td>8.07.2024</td>
        </tr>
        -->
        <tr>
          <td><b>Workshop Date</b></td>
          <td>Saturday, July 27th, 2024 @ Lehar 4, Messe Wien Exhibition Congress Center, Vienna</td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<br />
<hr />

<div class="row" id="cfp">
  <div class="col-xs-12">
    <h2>Call for Papers</h2>
    <br />
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
        <p>
            We invite submissions to the ICL 2024 workshop, focusing on the development of new architectures, algorithms, theoretical analysis, empirical studies, and applications of In-Context Learning (ICL). Submissions must present original research that has not been previously published. 
        </p>
        <p>Specific topics of interest include, but are not limited to:</p>
        <ul>
<li>architectures, training paradigms, and inductive biases that enable or improve ICL;</li>
<li>theoretical analyses and guarantees for ICL methods;</li>
<li>empirical evaluation of the performance of ICL on interpretability, controllability, and safety considerations for ICL systems;</li>
<li>similarities and differences between ICL in large-scale language modeling systems and learned algorithms in other domains;</li>
<li>the relationship between ICL and few-shot learning, meta-learning and automated machine learning (AutoML).</li>
        </ul>
        <p>Accepted papers will be presented as posters and a subset will be selected for oral presentation. The ICL 2024 workshop will be held in person at ICML 2024 with virtual participation options to be determined.
</p>

        <h3>Submission Guidelines</h3>
        <br />
        <p>
        We welcome both <b>long</b> (up to 8 pages) and <b>short</b> papers (up to 4 pages); the track can be selected during submission.
        Submitted manuscripts should be composed of a page-limited main body followed by an unlimited number of pages for references and appendices, all in a single file.
          Submissions should be uploaded via the <a class="red" href="https://openreview.net/group?id=ICML.cc/2024/Workshop/ICL">ICML 2024 Workshop ICL Submission</a> portal on OpenReview.
        </p>
        <p>Paper templates and style files (adapted from the ICML template) can be found in <a class="red" href="https://www.overleaf.com/read/mcmwbswdxwgq#4ee6ba">this Overleaf template</a>. Submissions must follow the template and style, be properly <b>anonymized (for double-blind review)</b>, and not exceed the page limits for the specified track (excluding references and appendices). We will <b>have non-archival proceedings</b>, but will share accepted papers and their reviews on OpenReview. We encourage including code in papers, though we ask to anonymize the code along with the submission.</p>
        <h3>Dual Submission Policy</h3>
        <br />
        <p>We aim to host work-in-preparation that would most benefit from feedback, which informs our dual submission policy.  We accept submissions that are <b>currently under review</b> for publication in other venues. However, as per ICML guidelines, we do not accept works <b>accepted for publication</b> in another archival venue as of the date of the workshop deadline. A work accepted at ICML 2024 or KDD 2024 can thus <b>not</b> be submitted to the workshop, but a paper under review at NeurIPS 2024 would be eligible.</p>
<!--
        <h3>Review Process</h3>
        <br />
        <p>
We will ask each reviewer to evaluate 1–2 submissions starting the week of Tuesday, May 28th. All reviews will be due no later than Friday, June 7th, anywhere on earth, to enable us to notify authors on time. Our active review period is thus between <b>May 28th and June 7th</b>.
</p>
        <h3>Author-Reviewer Policy</h3>
        <br />
        <p>
The workshop program committee plays an important role in identifying and giving feedback on up-and-coming work that would most benefit from discussion and visibility at the workshop.
To sustain our review and program selection processes, we require <b>at least one author of each submitted paper to volunteer to participate as a reviewer (and to accept if selected by the Organizers)</b> for the ICL 2024 workshop (identified in the OpenReview submission form).
</p>
        <h3>Call for Reviewers</h3>
        <br />
        <p>If you are interested in reviewing papers for the workshop outside of the author-reviewer requirements, we invite you to nominate yourself and/or others to serve on the program committee by filling out the <a class="red" href="https://forms.gle/j8jSDxMEVmTHKqfr5">reviewer nomination form
</a>.</p>
-->
  </div>
</div>

<br />
<hr />

<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2>Speakers</h2>
    <br />
  </div>
</div>
<div class="row">
  <div class="col-xs-6 col-lg-4 people">
    <a href="https://ekinakyurek.github.io">
      <img class="people-pic" src="{{ "/static/img/people/ekin_akyürek.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://ekinakyurek.github.io">Ekin Akyürek</a>
      <h6>Massachusetts Institute of Technology</h6>
    </div>
  </div>  
  <div class="col-xs-6 col-lg-4 people">
    <a href="https://scholar.google.com/citations?user=L79ecZkAAAAJ&hl=en&oi=sra">
      <img class="people-pic" src="{{ "/static/img/people/mehran_kazemi.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=L79ecZkAAAAJ&hl=en&oi=sra">Mehran Kazemi</a>
      <h6>Google Research</h6>
    </div>
  </div>

  <div class="col-xs-6 col-lg-4 people">
    <a href="https://scholar.google.com/citations?user=pevYEjAAAAAJ&hl=en&oi=ao">
      <img class="people-pic" src="{{ "/static/img/people/samuel_mueller.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=pevYEjAAAAAJ&hl=en&oi=ao">Samuel Müller</a>
      <h6>University of Freiburg</h6>
    </div>
  </div>
  </div>
  <div class="row">
  <div class="col-xs-6 col-lg-4 people">
    <a href="https://scholar.google.com/citations?user=bXOt49QAAAAJ&hl=en&oi=ao">
      <img class="people-pic" src="{{ "/static/img/people/stephanie_chan.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=bXOt49QAAAAJ&hl=en&oi=ao">Stephanie Chan</a>
      <h6>Google DeepMind</h6>
    </div>
  </div>
  
  <div class="col-xs-6 col-lg-4 people">
    <a href="https://scholar.google.com/citations?user=9uWgjIUAAAAJ&hl=en">
      <img class="people-pic" src="{{ "/static/img/people/yingcong_li.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=9uWgjIUAAAAJ&hl=en">Yingcong Li</a>
      <h6>University of Michigan, Ann Arbor</h6>
    </div>
  </div>
</div>
<br/>
<br/>
<hr />
<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Organizers</h2>
    <br />
  </div>
</div>
<div class="row">
  <div class="col-xs-6 col-lg-4 people">
    <a href="https://scholar.google.com/citations?user=v2cMiCAAAAAJ&hl=en">
      <img class="people-pic" src="{{ "/static/img/people/beyza_ermis.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=v2cMiCAAAAAJ&hl=en">Beyza Ermiş</a>
      <h6>Cohere</h6>
    </div>
  </div>

  <div class="col-xs-6 col-lg-4 people">
    <a href="https://eringrant.github.io">
      <img class="people-pic" src="{{ "/static/img/people/erin_grant.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://eringrant.github.io">Erin Grant</a>
      <h6>University College London</h6>
    </div>
  </div>

  <div class="col-xs-6 col-lg-4 people">
    <a href="https://ml.informatik.uni-freiburg.de/profile/hutter/">
      <img class="people-pic" src="{{ "/static/img/people/frank_hutter.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://ml.informatik.uni-freiburg.de/profile/hutter/">Frank Hutter</a>
      <h6>University of Freiburg</h6>
    </div>
  </div>
</div>
<div class="row">

  <div class="col-xs-6 col-lg-4 people">
    <a href="https://lmb.informatik.uni-freiburg.de/people/bratulic/">
      <img class="people-pic" src="{{ "/static/img/people/jelena_bratulic.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://lmb.informatik.uni-freiburg.de/people/bratulic/">Jelena Bratulić</a>
      <h6>University of Freiburg</h6>
    </div>
  </div>


  <div class="col-xs-6 col-lg-4 people">
    <a href="https://juliensiems.github.io">
      <img class="people-pic" src="{{ "/static/img/people/julien_siems.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://juliensiems.github.io">Julien Siems</a>
      <h6>University of Freiburg</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4 people">
    <a href="https://scholar.google.com/citations?hl=en&user=qGlN7KkAAAAJ">
      <img class="people-pic" src="{{ "/static/img/people/noah_hollmann.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?hl=en&user=qGlN7KkAAAAJ">Noah Hollmann</a>
      <h6>University of Freiburg & Charité Berlin</h6>
    </div>
  </div>
<br/>
</div>
  <br/>
<br/>
<hr />

<div class="row" id="sponsors">
  <div class="col-xs-12">
    <h2>Sponsors</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <br />
    We thank <a href="https://www.quantco.com/">QuantCo</a> for their generous support for this workshop!
    <div class="col-xs-6 col-lg-12 people">
    <a href="https://www.quantco.com/">
      <img class="people-pic" src="{{ "/static/img/quantco.jpeg" | prepend:site.baseurl }}">
    </a>
  </div>
</div>
</div>
<br/>
<br/>
<hr />

<div class="row" id="accepted">
  <div class="col-xs-12">
    <h2>Accepted Papers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
        <ul class="papers">

            <li class="paper">
                <a href="https://openreview.net/forum?id=zGyPLns0v7">Improve Temporal Awareness of LLMs for Domain-general Sequential Recommendation</a>
                <p>Authors: Zhendong Chu,  Zichao Wang,  Ruiyi Zhang,  Yangfeng Ji,  Hongning Wang,  Tong Sun</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=yV6acl90Fq">In-Context Principle Learning from Mistakes</a>
                <p>Authors: Tianjun Zhang,  Aman Madaan,  Luyu Gao,  Steven Zhang,  Swaroop Mishra,  Yiming Yang,  Niket Tandon,  Uri Alon</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=y0PQVjMbRf">In-Context Symmetries: Self-Supervised Learning through Contextual World Models</a>
                <p>Authors: Sharut Gupta,  Chenyu Wang,  Yifei Wang,  Tommi S. Jaakkola,  Stefanie Jegelka</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=xTfvKvVmAM">Localized Zeroth-Order Prompt Optimization</a>
                <p>Authors: Wenyang Hu,  Yao Shu,  Zongmin Yu,  Zhaoxuan Wu,  Xiaoqiang Lin,  Zhongxiang Dai,  See-Kiong Ng,  Bryan Kian Hsiang Low</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=vD0bP7GLHg">Fast Training Dataset Attribution via In-Context Learning</a>
                <p>Authors: Milad fotouhi,  Mohammad Taha Bahadori,  Oluwaseyi Feyisetan,  Payman Arabshahi, David Heckerman</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=uwkYY4Y8I1">In-context learning in presence of spurious correlations</a>
                <p>Authors: Hrayr Harutyunyan,  Rafayel Darbinyan,  Samvel Karapetyan,  Hrant Khachatrian</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=uILj5HPrag">DETAIL: Task DEmonsTration Attribution for Interpretable In-context Learning</a>
                <p>Authors: Zijian Zhou,  Xiaoqiang Lin,  Xinyi Xu,  Alok Prakash,  Daniela Rus,  Bryan Kian Hsiang Low</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=tntVlbDdoD">TabMDA: Tabular Manifold Data Augmentation for Any Classifier using Transformers with In-context Subsetting</a>
                <p>Authors: Andrei Margeloiu,  Adrián Bazaga,  Nikola Simidjievski,  Pietro Lio,  Mateja Jamnik</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=rfCtCcPuSt">Probing the Decision Boundaries of In-context  Learning in Large Language Models</a>
                <p>Authors: Siyan Zhao,  Tung Nguyen,  Aditya Grover</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=mEqddgqf5w">Transformers Learn Temporal Difference Methods for In-Context  Reinforcement Learning</a>
                <p>Authors: Jiuqi Wang,  Ethan Blaser,  Hadi Daneshmand,  Shangtong Zhang</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=j2rKwWXdcz">Many-Shot In-Context Learning in Multimodal Foundation Models</a>
                <p>Authors: Yixing Jiang,  Jeremy Andrew Irvin,  Ji Hun Wang,  Muhammad Ahmed Chaudhry,  Jonathan H Chen,  Andrew Y. Ng</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=goi7DFHlqS">Many-shot In-Context Learning</a>
                <p>Authors: Rishabh Agarwal,  Avi Singh,  Lei M Zhang,  Bernd Bohnet,  Luis Rosias,  Stephanie C.Y. Chan,  Biao Zhang,  Aleksandra Faust,  Hugo Larochelle</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=Zvwwnfwxa4">How In-Context Learning Emerges from Training on Unstructured Data: The Role of Co-Occurrence, Positional Information, and Noise Structures</a>
                <p>Authors: Kevin Christian Wibisono,  Yixin Wang</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=XWRvcEaqan">Automatic Domain Adaptation by Transformers in In-Context Learning</a>
                <p>Authors: Ryuichiro Hataya,  Kota Matsui,  Masaaki Imaizumi</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=XHP3t1AUp3">A Theoretical Understanding of Self-Correction through In-context Alignment</a>
                <p>Authors: Yifei Wang,  Yuyang Wu,  Zeming Wei,  Stefanie Jegelka,  Yisen Wang</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=XDzS9lCfQc">Learning Fast and Slow: Representations for In-Context Weight Modulation</a>
                <p>Authors: Andrey Zhmoginov,  Jihwan Lee,  Max Vladymyrov,  Mark Sandler</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=WjrKBQTWKp">Transformers are Minimax Optimal Nonparametric In-Context Learners</a>
                <p>Authors: Juno Kim,  Tai Nakamaki,  Taiji Suzuki</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=TYxOXHYU6b">Prompt Optimization with EASE? Efficient Ordering-aware Automated Selection of Exemplars</a>
                <p>Authors: Zhaoxuan Wu,  Xiaoqiang Lin,  Zhongxiang Dai,  Wenyang Hu,  Yao Shu,  See-Kiong Ng,  Patrick Jaillet,  Bryan Kian Hsiang Low</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=Qf4qZgDDj6">Can Transformers Solve Least Squares to High Precision?</a>
                <p>Authors: Jerry Weihong Liu,  Jessica Grogan,  Owen M Dugan,  Simran Arora,  Atri Rudra,  Christopher Re</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=MWV9zfgW9s">Linear Transformers are Versatile In-Context Learners</a>
                <p>Authors: Max Vladymyrov,  Johannes Von Oswald,  Mark Sandler,  Rong Ge</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=MOgg2cEms5">Transformers Can Perform Distributionally-robust Optimisation through In-context Learning</a>
                <p>Authors: Taeyoung Kim,  Hongseok Yang</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=M1v4y0rbFS">In-Context Generalization to New Tasks From Unlabeled Observation Data</a>
                <p>Authors: Anthony Liang,  Pavel Czempin,  Yutai Zhou,  Stephen Tu,  Erdem Biyik</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=LjsjHF7nAN">Universal Self-Consistency for Large Language Models</a>
                <p>Authors: Xinyun Chen,  Renat Aksitov,  Uri Alon,  Jie Ren,  Kefan Xiao,  Pengcheng Yin,  Sushant Prakash,  Charles Sutton,  Xuezhi Wang,  Denny Zhou</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=LN5X5rdlb3">Retrieval & Fine-Tuning for In-Context Tabular Models</a>
                <p>Authors: Valentin Thomas,  Junwei Ma,  Rasa Hosseinzadeh,  Keyvan Golestan,  Guangwei Yu,  Maksims Volkovs,  Anthony L. Caterini</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=LFEzQwYSQS">Can Mamba In-Context Learn Task Mixtures?</a>
                <p>Authors: Yingcong Li,  Xupeng Wei,  Haonan Zhao, Taigao Ma</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=JMvxJeuW8B">Learning Task Representations from In-Context Learning</a>
                <p>Authors: Baturay Saglam,  Zhuoran Yang,  Dionysis Kalogerias,  Amin Karbasi</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=Ig9jEr8qCN">An In-Context Learning Theoretic Analysis of Chain-of-Thought</a>
                <p>Authors: Chenxiao Yang,  Zhiyuan Li,  David Wipf</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=FraikHzMu9">Can LLMs predict the convergence of Stochastic Gradient Descent?</a>
                <p>Authors: Oussama Zekri,  Abdelhakim Benechehab,  Ievgen Redko</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=CzcCUzJQER">Cross-lingual QA: A Key to Unlocking In-context Cross-lingual Performance</a>
                <p>Authors: Sunkyoung Kim,  Dayeon Ki,  Yireun Kim,  Jinsik Lee</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=C60IT3ScL4">LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language</a>
                <p>Authors: John F Bronskill,  James Requeima,  Dami Choi,  Richard E Turner,  David Duvenaud</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=ANeHJIoF54">LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law</a>
                <p>Authors: Toni J.B. Liu,  Nicolas Boulle,  Raphaël Sarfati,  Christopher Earls</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=9QI3E2iaSD">In-Context Learning of Energy Functions</a>
                <p>Authors: Rylan Schaeffer,  Mikail Khona,  Sanmi Koyejo</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=8Xku9fR8dR">Polynomial Regression as a Task for Understanding In-context Learning Through Finetuning and Alignment</a>
                <p>Authors: Max Wilcoxson,  Morten Svendgård,  Ria Doshi,  Dylan Davis,  Reya Vir,  Anant Sahai</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=8KpkKsGjED">Can large language models explore in-context?</a>
                <p>Authors: Akshay Krishnamurthy,  Keegan Harris,  Dylan J Foster,  Cyril Zhang,  Aleksandrs Slivkins</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=8Dey9wo2qA">In-Context Reinforcement Learning Without Optimal Action Labels</a>
                <p>Authors: Juncheng Dong,  Moyang Guo,  Ethan X Fang,  Zhuoran Yang,  Vahid Tarokh</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=4SfCI1DJhr">Task Descriptors Help Transformers Learn Linear Models In-Context</a>
                <p>Authors: Ruomin Huang,  Rong Ge</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=4FRXFBSM2A">Transformers as Stochastic Optimizers</a>
                <p>Authors: Ryuichiro Hataya,  Masaaki Imaizumi</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=3kFfldGNwg">Verbalized Machine Learning: Revisiting Machine Learning with Language Models</a>
                <p>Authors: Tim Z. Xiao,  Robert Bamler,  Bernhard Schölkopf,  Weiyang Liu</p>
            </li>
    
            <li class="paper">
                <a href="https://openreview.net/forum?id=1vM1a7KrC6">Fine-grained Analysis of In-context Linear Estimation</a>
                <p>Authors: Yingcong Li,  Ankit Singh Rawat,  Samet Oymak</p>
            </li>
    
        </ul>
    </div>
</div>

<br/>
<br/>
<hr />

<div class="text-center p-3" style="background-color: rgba(0, 0, 0, 0)">
    <h6>
        Website theme adapted from the <a href="https://github.com/sslrlworkshop/sslrlworkshop.github.io">SSL-RL workshop</a>
        which was adapted from the <a href="https://github.com/vigilworkshop/vigilworkshop.github.io">VIGIL workshop</a>.
    </h6>
    <br>
</div>
